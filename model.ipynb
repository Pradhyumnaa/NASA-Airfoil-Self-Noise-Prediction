{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying if the SSPL Column follows a Normal Distribution\n",
    "\n",
    "If it does, we can use the Standard Deviation to create the acceptable range like this: Actual Value+-ySD where y is an appropriate factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"AirfoilSelfNoise.csv\")\n",
    "\n",
    "# Extract the SSPL column\n",
    "sspl_data = data['SSPL']\n",
    "\n",
    "# Plot a histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(sspl_data, bins=30, edgecolor='k')\n",
    "plt.xlabel('SSPL')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of SSPL')\n",
    "plt.show()\n",
    "\n",
    "# Create a Q-Q plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "stats.probplot(sspl_data, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of SSPL')\n",
    "plt.show()\n",
    "\n",
    "# Perform Shapiro-Wilk test\n",
    "statistic, p_value = stats.shapiro(sspl_data)\n",
    "print(\"Shapiro-Wilk Test:\")\n",
    "print(\"Statistic:\", statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not a Normal Distribution and Trying IQR\n",
    "\n",
    "Based on the histogram, we can conclude that the SSPL column has a negative skew and thus, we cannot use the SD as a value for the range. For this reason, we can try to use the IQR to create the range as the IQR is more resistant to skews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract the SSPL column\n",
    "sspl_data = data['SSPL']\n",
    "\n",
    "std = np.std(sspl_data)\n",
    "\n",
    "print(\"Standard Deviation:\", std)\n",
    "\n",
    "# Calculate the IQR\n",
    "q1 = np.percentile(sspl_data, 25)\n",
    "q3 = np.percentile(sspl_data, 75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "print(\"Interquartile Range (IQR):\", iqr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding a suitable factor for IQR\n",
    "\n",
    "Since the IQR is 9.8 (close to 10), we cannot use it as is. Decibels follow a logarithmic increase, where an increase of 10db means the sound is 10 times louder. So I've set the suitable factor to be 0.5 but if accuracy is of the highest priority, this factor can be decreased.\n",
    "\n",
    "# Starting with Model Creation\n",
    "\n",
    "First comes data processing to ensure all the data is an acceptable format, then comes the model and finally, an evaluation based on how many values in the test set fall within the acceptable range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "train_data = pd.read_csv('training_set.csv')\n",
    "val_data = pd.read_csv('validation_set.csv')\n",
    "test_data = pd.read_csv('test_set.csv')\n",
    "\n",
    "# Step 2: Prepare the data\n",
    "X_train = train_data[['f', 'alpha', 'c', 'U_infinity', 'delta']].values\n",
    "y_train = train_data['SSPL'].values\n",
    "\n",
    "X_val = val_data[['f', 'alpha', 'c', 'U_infinity', 'delta']].values\n",
    "y_val = val_data['SSPL'].values\n",
    "\n",
    "X_test = test_data[['f', 'alpha', 'c', 'U_infinity', 'delta']].values\n",
    "y_test = test_data['SSPL'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1, 5)  # Reshape training data\n",
    "X_val = X_val.reshape(-1, 1, 5)  # Reshape validation data\n",
    "X_test = X_test.reshape(-1, 1, 5)  # Reshape test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build the model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(128, activation='relu'), input_shape=(1, 5)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "model.fit(X_train, y_train, batch_size=16, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Calculate how many predictions fall within the range of ActualValue+-IQR*0.5\n",
    "count_within_range = 0\n",
    "\n",
    "# Print actual vs predicted values and count predictions within range\n",
    "for i in range(len(y_pred)):\n",
    "    print(f\"Actual: {y_test[i]}, Predicted: {y_pred[i]}\")\n",
    "    if y_test[i] - iqr*0.5 <= y_pred[i] <= y_test[i] + iqr*0.5:\n",
    "        count_within_range += 1\n",
    "\n",
    "print(\"Count within range:\", count_within_range/len(y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics of 10 Runs\n",
    "\n",
    "Predictions within Range: 91,95,93,93,92,86,86,89,86,89\n",
    "Mean, μ: 90\n",
    "Standard Deviation, σ: 3.1304951684997\n",
    "\n",
    "From this, we can conclude the model is performing well, with minimal inconsistency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
